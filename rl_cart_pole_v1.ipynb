{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt\n!apt install -y python-opengl ffmpeg xvfb\n!pip install pyvirtualdisplay pyglet==1.5.1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T14:34:48.146058Z","iopub.execute_input":"2024-05-08T14:34:48.146817Z","iopub.status.idle":"2024-05-08T14:35:36.171538Z","shell.execute_reply.started":"2024-05-08T14:34:48.146786Z","shell.execute_reply":"2024-05-08T14:35:36.170380Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/ntasfi/PyGame-Learning-Environment.git (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 1))\n  Cloning https://github.com/ntasfi/PyGame-Learning-Environment.git to /tmp/pip-req-build-10elqqam\n  Running command git clone --filter=blob:none --quiet https://github.com/ntasfi/PyGame-Learning-Environment.git /tmp/pip-req-build-10elqqam\n  Resolved https://github.com/ntasfi/PyGame-Learning-Environment.git to commit 3dbe79dc0c35559bb441b9359948aabf9bb3d331\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting git+https://github.com/simoninithomas/gym-games (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2))\n  Cloning https://github.com/simoninithomas/gym-games to /tmp/pip-req-build-gu43plhs\n  Running command git clone --filter=blob:none --quiet https://github.com/simoninithomas/gym-games /tmp/pip-req-build-gu43plhs\n  Resolved https://github.com/simoninithomas/gym-games to commit f31695e4ba028400628dc054ee8a436f28193f0b\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (0.22.2)\nCollecting imageio-ffmpeg (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 4))\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\nCollecting pyyaml==6.0 (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 5))\n  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ple==0.0.1->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 1)) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from ple==0.0.1->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 1)) (9.5.0)\nRequirement already satisfied: gym>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (0.26.2)\nRequirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (69.0.3)\nCollecting pygame>=1.9.6 (from gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2))\n  Downloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (4.9.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym>=0.13.0->gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym>=0.13.0->gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (0.0.8)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2024.2.2)\nDownloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ple, gym-games\n  Building wheel for ple (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ple: filename=ple-0.0.1-py3-none-any.whl size=50769 sha256=97e1c5bb795ed583209f973051aa9967657bc4d94ba1d285361a0e8a1004f22e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-fty3dcoc/wheels/f8/31/ca/a64a7ce73540465412d82813780d062db53b90e3f42a4ecb7f\n  Building wheel for gym-games (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gym-games: filename=gym_games-1.0.4-py3-none-any.whl size=17304 sha256=8de8a7a990d379a0c89a9f76aefd9441886ced4cbbae55ea32c83f0f29c65688\n  Stored in directory: /tmp/pip-ephem-wheel-cache-fty3dcoc/wheels/ca/bf/6b/7d631626202ebb033c908a688d1862ff4d948c34cf621d7dc9\nSuccessfully built ple gym-games\nInstalling collected packages: pyyaml, pygame, ple, imageio-ffmpeg, gym-games\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0.1\n    Uninstalling PyYAML-6.0.1:\n      Successfully uninstalled PyYAML-6.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gym-games-1.0.4 imageio-ffmpeg-0.4.9 ple-0.0.1 pygame-2.5.2 pyyaml-6.0\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\nxvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.17).\nThe following additional packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python2 python2-minimal python2.7 python2.7-minimal\nSuggested packages:\n  python-tk python-numpy libgle3 python2-doc python2.7-doc binfmt-support\nThe following NEW packages will be installed:\n  freeglut3 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n  libpython2.7-stdlib python-opengl python2 python2-minimal python2.7\n  python2.7-minimal\n0 upgraded, 10 newly installed, 0 to remove and 65 not upgraded.\nNeed to get 4540 kB of archives.\nAfter this operation, 22.7 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-minimal amd64 2.7.18-1~20.04.4 [335 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7-minimal amd64 2.7.18-1~20.04.4 [1280 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-stdlib amd64 2.7.18-1~20.04.4 [1887 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7 amd64 2.7.18-1~20.04.4 [248 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7072 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libglu1-mesa amd64 9.0.1-1build1 [168 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\nFetched 4540 kB in 0s (15.2 MB/s)        \u001b[0m\u001b[33m\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libpython2.7-minimal:amd64.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../0-libpython2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [##........................................................] \u001b8Selecting previously unselected package python2.7-minimal.\nPreparing to unpack .../1-python2.7-minimal_2.7.18-1~20.04.4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking python2.7-minimal (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package python2-minimal.\nPreparing to unpack .../2-python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libpython2.7-stdlib:amd64.\nPreparing to unpack .../3-libpython2.7-stdlib_2.7.18-1~20.04.4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package python2.7.\nPreparing to unpack .../4-python2.7_2.7.18-1~20.04.4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking python2.7 (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package libpython2-stdlib:amd64.\nPreparing to unpack .../5-libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Setting up libpython2.7-minimal:amd64 (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Setting up python2.7-minimal (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Linking and byte-compiling packages for runtime python2.7...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Setting up python2-minimal (2.7.17-2ubuntu4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [########################..................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package python2.\n(Reading database ... 114554 files and directories currently installed.)\nPreparing to unpack .../python2_2.7.17-2ubuntu4_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking python2 (2.7.17-2ubuntu4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Selecting previously unselected package freeglut3:amd64.\nPreparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Unpacking freeglut3:amd64 (2.8.1-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Selecting previously unselected package libglu1-mesa:amd64.\nPreparing to unpack .../libglu1-mesa_9.0.1-1build1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Unpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Selecting previously unselected package python-opengl.\nPreparing to unpack .../python-opengl_3.1.0+dfsg-2build1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up freeglut3:amd64 (2.8.1-3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libpython2.7-stdlib:amd64 (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up libglu1-mesa:amd64 (9.0.1-1build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up python2.7 (2.7.18-1~20.04.4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up python2 (2.7.17-2ubuntu4) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up python-opengl (3.1.0+dfsg-2build1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for man-db (2.9.1-1) ...\nProcessing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\nCollecting pyglet==1.5.1\n  Downloading pyglet-1.5.1-py2.py3-none-any.whl.metadata (7.6 kB)\nDownloading pyglet-1.5.1-py2.py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay, pyglet\nSuccessfully installed pyglet-1.5.1 pyvirtualdisplay-3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport datetime\nimport json\nimport os\nimport tempfile\n\nfrom collections import deque\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.distributions import Categorical\n\nimport gym\n\nfrom huggingface_hub import notebook_login, HfApi, snapshot_download\nfrom huggingface_hub.repocard import metadata_eval_result, metadata_save\n\nimport imageio\nfrom pathlib import Path\nfrom pyvirtualdisplay import Display","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:36.173624Z","iopub.execute_input":"2024-05-08T14:35:36.173925Z","iopub.status.idle":"2024-05-08T14:35:40.286338Z","shell.execute_reply.started":"2024-05-08T14:35:36.173898Z","shell.execute_reply":"2024-05-08T14:35:40.285525Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Policy(nn.Module):\n    def __init__(self, s_size, a_size, h_size):\n        super(Policy, self).__init__()\n        self.fc1 = nn.Linear(s_size, h_size)\n        self.fc2 = nn.Linear(h_size, a_size)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.softmax(x, dim=1)\n\n    def act(self, state):\n        state = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n        probs = self.forward(state).cpu()\n        m = Categorical(probs)\n        action = m.sample()\n        return action.item(), m.log_prob(action)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:40.287450Z","iopub.execute_input":"2024-05-08T14:35:40.287821Z","iopub.status.idle":"2024-05-08T14:35:40.295436Z","shell.execute_reply.started":"2024-05-08T14:35:40.287795Z","shell.execute_reply":"2024-05-08T14:35:40.294418Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every):\n    scores_deque = deque(maxlen=100)\n    scores = []\n    for i_episode in range(1, n_training_episodes + 1):\n        saved_log_probs = []\n        rewards = []\n        state = env.reset()[0]\n        for t in range(max_t):\n            action, log_prob = policy.act(state)\n            saved_log_probs.append(log_prob)\n            state, reward, done, _, _ = env.step(action)\n            rewards.append(reward)\n            if done:\n                break\n        scores_deque.append(sum(rewards))\n        scores.append(sum(rewards))\n\n        returns = deque(maxlen=max_t)\n        n_steps = len(rewards)\n       \n        for t in range(n_steps)[::-1]:\n            disc_return_t = returns[0] if len(returns) > 0 else 0\n            returns.appendleft(gamma * disc_return_t + rewards[t])\n\n        eps = np.finfo(np.float32).eps.item()\n        returns = torch.tensor(returns)\n        returns = (returns - returns.mean()) / (returns.std() + eps)\n\n        policy_loss = []\n        for log_prob, disc_return in zip(saved_log_probs, returns):\n            policy_loss.append(-log_prob * disc_return)\n        policy_loss = torch.cat(policy_loss).sum()\n\n        optimizer.zero_grad()\n        policy_loss.backward()\n        optimizer.step()\n\n        if i_episode % print_every == 0:\n            print(\"Episode {}\\tAverage Score: {:.2f}\".format(i_episode, np.mean(scores_deque)))\n\n    return scores\n\n\ndef evaluate_agent(env, max_steps, n_eval_episodes, policy):\n    \"\"\"\n    Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n    :param env: The evaluation environment\n    :param n_eval_episodes: Number of episode to evaluate the agent\n    :param policy: The Reinforce agent\n    \"\"\"\n    episode_rewards = []\n    for episode in range(n_eval_episodes):\n        state = env.reset()[0]\n        step = 0\n        done = False\n        total_rewards_ep = 0\n\n        for step in range(max_steps):\n            action, _ = policy.act(state)\n            new_state, reward, done, info, _ = env.step(action)\n            total_rewards_ep += reward\n\n            if done:\n                break\n            state = new_state\n        episode_rewards.append(total_rewards_ep)\n    mean_reward = np.mean(episode_rewards)\n    std_reward = np.std(episode_rewards)\n\n    return mean_reward, std_reward\n\n\ndef record_video(env, policy, out_directory, fps=30):\n    \"\"\"\n    Generate a replay video of the agent\n    :param env\n    :param out_directory\n    :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n    \"\"\"\n    images = []\n    done = False\n    state = env.reset()[0]\n    img = env.render()\n    images.append(img)\n    while not done:\n        # Take the action (index) that have the maximum expected future reward given that state\n        action, _ = policy.act(state)\n        state, reward, done, info, _ = env.step(action)  # We directly put next_state = state for recording logic\n        img = env.render()\n        images.append(img)\n        \n    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n    \n\ndef push_to_hub(repo_id,\n                model,\n                hyperparameters,\n                eval_env,\n                video_fps=30\n                ):\n  \"\"\"\n  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n  This method does the complete pipeline:\n  - It evaluates the model\n  - It generates the model card\n  - It generates a replay video of the agent\n  - It pushes everything to the Hub\n\n  :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n  :param model: the pytorch model we want to save\n  :param hyperparameters: training hyperparameters\n  :param eval_env: evaluation environment\n  :param video_fps: how many frame per seconds to record our video replay\n  \"\"\"\n\n  _, repo_name = repo_id.split(\"/\")\n  api = HfApi()\n\n  # Step 1: Create the repo\n  repo_url = api.create_repo(\n        repo_id=repo_id,\n        exist_ok=True,\n  )\n\n  with tempfile.TemporaryDirectory() as tmpdirname:\n    local_directory = Path(tmpdirname)\n\n    # Step 2: Save the model\n    torch.save(model, local_directory / \"model.pt\")\n\n    # Step 3: Save the hyperparameters to JSON\n    with open(local_directory / \"hyperparameters.json\", \"w\") as outfile:\n      json.dump(hyperparameters, outfile)\n\n    # Step 4: Evaluate the model and build JSON\n    mean_reward, std_reward = evaluate_agent(eval_env,\n                                            hyperparameters[\"max_t\"],\n                                            hyperparameters[\"n_evaluation_episodes\"],\n                                            model)\n    # Get datetime\n    eval_datetime = datetime.datetime.now()\n    eval_form_datetime = eval_datetime.isoformat()\n\n    evaluate_data = {\n          \"env_id\": hyperparameters[\"env_id\"],\n          \"mean_reward\": mean_reward,\n          \"n_evaluation_episodes\": hyperparameters[\"n_evaluation_episodes\"],\n          \"eval_datetime\": eval_form_datetime,\n    }\n\n    # Write a JSON file\n    with open(local_directory / \"results.json\", \"w\") as outfile:\n        json.dump(evaluate_data, outfile)\n\n    # Step 5: Create the model card\n    env_name = hyperparameters[\"env_id\"]\n\n    metadata = {}\n    metadata[\"tags\"] = [\n          env_name,\n          \"reinforce\",\n          \"reinforcement-learning\",\n          \"custom-implementation\",\n          \"deep-rl-class\"\n      ]\n\n    # Add metrics\n    eval = metadata_eval_result(\n        model_pretty_name=repo_name,\n        task_pretty_name=\"reinforcement-learning\",\n        task_id=\"reinforcement-learning\",\n        metrics_pretty_name=\"mean_reward\",\n        metrics_id=\"mean_reward\",\n        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n        dataset_pretty_name=env_name,\n        dataset_id=env_name,\n      )\n\n    # Merges both dictionaries\n    metadata = {**metadata, **eval}\n\n    model_card = f\"\"\"\n      # **Reinforce** Agent playing **{env_id}**\n      This is a trained model of a **Reinforce** agent playing **{env_id}** .\n      To learn to use this model and train yours check Unit 4 of the Deep Reinforcement Learning Course: https://huggingface.co/deep-rl-course/unit4/introduction\n      \"\"\"\n\n    readme_path = local_directory / \"README.md\"\n    readme = \"\"\n    if readme_path.exists():\n        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n          readme = f.read()\n    else:\n      readme = model_card\n\n    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n      f.write(readme)\n\n    # Save our metrics to Readme metadata\n    metadata_save(readme_path, metadata)\n\n    # Step 6: Record a video\n    #video_path =  local_directory / \"replay.mp4\"\n    #record_video(env, model, video_path, video_fps)\n\n    # Step 7. Push everything to the Hub\n    api.upload_folder(\n          repo_id=repo_id,\n          folder_path=local_directory,\n          path_in_repo=\".\",\n    )\n\n    print(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")    ","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:40.299465Z","iopub.execute_input":"2024-05-08T14:35:40.299814Z","iopub.status.idle":"2024-05-08T14:35:40.706399Z","shell.execute_reply.started":"2024-05-08T14:35:40.299783Z","shell.execute_reply":"2024-05-08T14:35:40.705447Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"virtual_display = Display(visible=0, size=(1400, 900))\nvirtual_display.start()","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:40.707617Z","iopub.execute_input":"2024-05-08T14:35:40.708034Z","iopub.status.idle":"2024-05-08T14:35:41.079100Z","shell.execute_reply.started":"2024-05-08T14:35:40.707985Z","shell.execute_reply":"2024-05-08T14:35:41.078102Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<pyvirtualdisplay.display.Display at 0x7ce783851b70>"},"metadata":{}}]},{"cell_type":"code","source":"env_id = \"CartPole-v1\"\nenv = gym.make(env_id, render_mode=\"rgb_array\")\n\neval_env = gym.make(env_id, render_mode=\"rgb_array\")\n\ns_size = env.observation_space.shape[0]\na_size = env.action_space.n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:41.080467Z","iopub.execute_input":"2024-05-08T14:35:41.080911Z","iopub.status.idle":"2024-05-08T14:35:41.095748Z","shell.execute_reply.started":"2024-05-08T14:35:41.080879Z","shell.execute_reply":"2024-05-08T14:35:41.094907Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"PARAMS = {\n    \"h_size\": 16,\n    \"n_training_episodes\": 1000,\n    \"n_evaluation_episodes\": 10,\n    \"max_t\": 1000,\n    \"gamma\": 1.0,\n    \"lr\": 1e-2,\n    \"env_id\": env_id,\n    \"state_space\": s_size,\n    \"action_space\": a_size,\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:41.096910Z","iopub.execute_input":"2024-05-08T14:35:41.097286Z","iopub.status.idle":"2024-05-08T14:35:41.102414Z","shell.execute_reply.started":"2024-05-08T14:35:41.097254Z","shell.execute_reply":"2024-05-08T14:35:41.101476Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nPOLICY = Policy(\n    PARAMS[\"state_space\"],\n    PARAMS[\"action_space\"],\n    PARAMS[\"h_size\"],\n).to(DEVICE)\n\nOPTIMIZER = optim.Adam(POLICY.parameters(), lr=PARAMS[\"lr\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:35:41.103809Z","iopub.execute_input":"2024-05-08T14:35:41.104414Z","iopub.status.idle":"2024-05-08T14:35:43.282487Z","shell.execute_reply.started":"2024-05-08T14:35:41.104381Z","shell.execute_reply":"2024-05-08T14:35:43.281518Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"scores = reinforce(\n    POLICY,\n    OPTIMIZER,\n    PARAMS[\"n_training_episodes\"],\n    PARAMS[\"max_t\"],\n    PARAMS[\"gamma\"],\n    100,\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T14:35:43.283714Z","iopub.execute_input":"2024-05-08T14:35:43.284092Z","iopub.status.idle":"2024-05-08T14:46:38.413994Z","shell.execute_reply.started":"2024-05-08T14:35:43.284067Z","shell.execute_reply":"2024-05-08T14:46:38.413057Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n  if not isinstance(terminated, (bool, np.bool8)):\n","output_type":"stream"},{"name":"stdout","text":"Episode 100\tAverage Score: 44.20\nEpisode 200\tAverage Score: 131.36\nEpisode 300\tAverage Score: 318.56\nEpisode 400\tAverage Score: 738.95\nEpisode 500\tAverage Score: 991.79\nEpisode 600\tAverage Score: 943.71\nEpisode 700\tAverage Score: 1000.00\nEpisode 800\tAverage Score: 992.93\nEpisode 900\tAverage Score: 1000.00\nEpisode 1000\tAverage Score: 970.54\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate_agent(\n    eval_env\n    , PARAMS[\"max_t\"]\n    , PARAMS[\"n_evaluation_episodes\"]\n    , POLICY\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:46:38.421369Z","iopub.execute_input":"2024-05-08T14:46:38.421768Z","iopub.status.idle":"2024-05-08T14:46:44.852499Z","shell.execute_reply.started":"2024-05-08T14:46:38.421741Z","shell.execute_reply":"2024-05-08T14:46:44.851596Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(1000.0, 0.0)"},"metadata":{}}]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:46:44.853538Z","iopub.execute_input":"2024-05-08T14:46:44.853803Z","iopub.status.idle":"2024-05-08T14:46:44.875355Z","shell.execute_reply.started":"2024-05-08T14:46:44.853779Z","shell.execute_reply":"2024-05-08T14:46:44.874165Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae4fd174d0bf4a68830f3fb0b7e06149"}},"metadata":{}}]},{"cell_type":"code","source":"repo_id = \"jaymanvirk/rl_cart_pole_v1\"\npush_to_hub(\n    repo_id,\n    POLICY, \n    PARAMS,  \n    eval_env,  \n    video_fps=30\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:47:10.954846Z","iopub.execute_input":"2024-05-08T14:47:10.955521Z","iopub.status.idle":"2024-05-08T14:50:11.309423Z","shell.execute_reply.started":"2024-05-08T14:47:10.955486Z","shell.execute_reply":"2024-05-08T14:50:11.308016Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjaymanvirk/rl_cart_pole_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPOLICY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPARAMS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_fps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[4], line 204\u001b[0m, in \u001b[0;36mpush_to_hub\u001b[0;34m(repo_id, model, hyperparameters, eval_env, video_fps)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Step 6: Record a video\u001b[39;00m\n\u001b[1;32m    203\u001b[0m video_path \u001b[38;5;241m=\u001b[39m  local_directory \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplay.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 204\u001b[0m \u001b[43mrecord_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_fps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# Step 7. Push everything to the Hub\u001b[39;00m\n\u001b[1;32m    207\u001b[0m api\u001b[38;5;241m.\u001b[39mupload_folder(\n\u001b[1;32m    208\u001b[0m       repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    209\u001b[0m       folder_path\u001b[38;5;241m=\u001b[39mlocal_directory,\n\u001b[1;32m    210\u001b[0m       path_in_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m )\n","Cell \u001b[0;32mIn[4], line 87\u001b[0m, in \u001b[0;36mrecord_video\u001b[0;34m(env, policy, out_directory, fps)\u001b[0m\n\u001b[1;32m     84\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Take the action (index) that have the maximum expected future reward given that state\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     state, reward, done, info, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)  \u001b[38;5;66;03m# We directly put next_state = state for recording logic\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     img \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender()\n","Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mPolicy.act\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     13\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(state)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     14\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(state)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m---> 15\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m action \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem(), m\u001b[38;5;241m.\u001b[39mlog_prob(action)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/categorical.py:70\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     67\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/distribution.py:67\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     65\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}